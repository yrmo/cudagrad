{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural networks included in [cudagrad](https://github.com/yrmo/cudagrad) are written purely in Python, using only the `cudagrad.Tensor` for learning. Ideally, this helps improve the `Tensor` class over time. Please see the repository for examples of the neural networks that can be made with `Tensor` currently ([flexing](https://youtu.be/VMj-3S1tku0?t=271s)).\n",
    "\n",
    "# Warning ðŸ²ðŸ‰\n",
    "\n",
    "This is an experimental learning project and will be unstable until version 1.0.0 as per [SemVer-4](https://semver.org/):\n",
    "\n",
    "> Major version zero (0.y.z) is for initial development. Anything MAY change at any time. The public API SHOULD NOT be considered stable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T22:03:55.886940Z",
     "iopub.status.busy": "2023-11-25T22:03:55.886331Z",
     "iopub.status.idle": "2023-11-25T22:03:55.904779Z",
     "shell.execute_reply": "2023-11-25T22:03:55.903889Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.1.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cudagrad\n",
    "\n",
    "cudagrad.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation\n",
    "\n",
    "Available on [PyPi](https://pypi.org/project/cudagrad/) using `pip install cudagrad`.\n",
    "\n",
    "As cudagrad is a [C++ extension to Python](https://docs.python.org/3/extending/building.html) (using [pybind11](https://github.com/pybind/pybind11)) that builds from source at installation time, you need to have a C++ compiler. Currently both `clang` and `gcc` are supported, but in the future, installation will also require NVIDIA's CUDA C++ compiler [`nvcc`](https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html), as well as `cmake`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "Copyright (C) 2021 Free Software Foundation, Inc.\n",
      "This is free software; see the source for copying conditions.  There is NO\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
      "\n",
      "Python 3.10.12\n",
      "pip 22.0.2 from /usr/lib/python3/dist-packages/pip (python 3.10)\n",
      "cmake version 3.22.1\n",
      "\n",
      "CMake suite maintained and supported by Kitware (kitware.com/cmake).\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\n",
      "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
      "Cuda compilation tools, release 12.2, V12.2.140\n",
      "Build cuda_12.2.r12.2/compiler.33191640_0\n"
     ]
    }
   ],
   "source": [
    "from os import system\n",
    "from shutil import which\n",
    "\n",
    "system(\"c++ --version\")\n",
    "system(\"python --version\")\n",
    "system(\"pip --version\")\n",
    "\n",
    "if which(\"cmake\") and which(\"nvcc\"):\n",
    "    system(\"cmake --version\")\n",
    "    system(\"nvcc --version\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T22:03:56.671642Z",
     "iopub.status.busy": "2023-11-25T22:03:56.671515Z",
     "iopub.status.idle": "2023-11-25T22:03:56.674426Z",
     "shell.execute_reply": "2023-11-25T22:03:56.674150Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2794.0]\n",
      "[1]\n",
      "[143.0, 187.0, 143.0, 187.0]\n",
      "[66.0, 66.0, 88.0, 88.0]\n"
     ]
    }
   ],
   "source": [
    "from cudagrad import Tensor\n",
    "\n",
    "a = Tensor([2, 2], [2.0, 3.0, 4.0, 5.0])\n",
    "b = Tensor([2, 2], [6.0, 7.0, 8.0, 9.0])\n",
    "c = Tensor([2, 2], [10.0, 10.0, 10.0, 10.0])\n",
    "d = Tensor([2, 2], [11.0, 11.0, 11.0, 11.0])\n",
    "e = Tensor.relu(((a @ b) + c) * d)\n",
    "f = e.sum()\n",
    "f.backward()\n",
    "\n",
    "print(f.data())\n",
    "print(f.size)\n",
    "print(a.grad())\n",
    "print(b.grad())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what that would look like using PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T22:03:56.675640Z",
     "iopub.status.busy": "2023-11-25T22:03:56.675452Z",
     "iopub.status.idle": "2023-11-25T22:03:56.686089Z",
     "shell.execute_reply": "2023-11-25T22:03:56.685808Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2794.)\n",
      "torch.Size([])\n",
      "tensor([[143., 187.],\n",
      "        [143., 187.]])\n",
      "tensor([[66., 66.],\n",
      "        [88., 88.]])\n"
     ]
    }
   ],
   "source": [
    "from torch import tensor, relu\n",
    "\n",
    "at = tensor(((2.0, 3.0), (4.0, 5.0)), requires_grad=True)\n",
    "bt = tensor(((6.0, 7.0), (8.0, 9.0)), requires_grad=True)\n",
    "ct = tensor(((10.0, 10.0), (10.0, 10.0)), requires_grad=True)\n",
    "dt = tensor(((11.0, 11.0), (11.0, 11.0)), requires_grad=True)\n",
    "et = relu(((at @ bt) + ct) * dt)\n",
    "ft = et.sum()\n",
    "ft.backward()\n",
    "\n",
    "print(ft.data)\n",
    "print(ft.size())\n",
    "print(at.grad)\n",
    "print(bt.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors in cudagrad are like PyTorch tensors, except:\n",
    "\n",
    "- Tensors only use `float32`\n",
    "- Tensors `requires_grad` by default\n",
    "- The `Tensor` constructor takes two lists instead of a nested list: `cudagrad.Tensor([size], [data])`\n",
    "  \n",
    "Known limitations:\n",
    "\n",
    "- Implicit broadcasting of tensors of rank > 2 during backpropagation has not yet been implemented, and will raise a runtime error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor `__init__`\n",
    "\n",
    "The data list is loaded in [row-major order](https://en.wikipedia.org/wiki/Row-_and_column-major_order) (left to right, top to bottom):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T22:03:55.932395Z",
     "iopub.status.busy": "2023-11-25T22:03:55.931839Z",
     "iopub.status.idle": "2023-11-25T22:03:55.935000Z",
     "shell.execute_reply": "2023-11-25T22:03:55.934738Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Tensor([2, 1, ], [0, 1, ]) object at 0x6098126e08f0 DefaultBackward>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cudagrad import Tensor\n",
    "\n",
    "t = Tensor([2, 1], range(2))\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We made a tensor that is a column matrix with the values of 0, and 1. This would be the same as the following in PyTorch for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T22:03:55.936396Z",
     "iopub.status.busy": "2023-11-25T22:03:55.936301Z",
     "iopub.status.idle": "2023-11-25T22:03:56.648365Z",
     "shell.execute_reply": "2023-11-25T22:03:56.647759Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [1.]], requires_grad=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import tensor, float32\n",
    "\n",
    "tensor([[0], [1]], dtype=float32, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Intro\n",
    "\n",
    "If we `print` this tensor two matrixes are printed, first the `data`, then the `grad`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T22:03:56.653908Z",
     "iopub.status.busy": "2023-11-25T22:03:56.653775Z",
     "iopub.status.idle": "2023-11-25T22:03:56.655706Z",
     "shell.execute_reply": "2023-11-25T22:03:56.655447Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0],\n",
      " [1]]\n",
      "[[0],\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Various operations are supported, far fewer than PyTorch, but I plan to grow this over time... At the moment some basics are supported:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T22:03:56.657134Z",
     "iopub.status.busy": "2023-11-25T22:03:56.657001Z",
     "iopub.status.idle": "2023-11-25T22:03:56.659111Z",
     "shell.execute_reply": "2023-11-25T22:03:56.658870Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Tensor([1, ], [2, ]) object at 0x6098126de510 SumBackward>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = (t + t).sum()\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might wondering why I show the address of the Tensor object, unlike PyTorch. It's because it's helpful for debugging, I use this myself for cudagrad's development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T22:03:56.660516Z",
     "iopub.status.busy": "2023-11-25T22:03:56.660387Z",
     "iopub.status.idle": "2023-11-25T22:03:56.662275Z",
     "shell.execute_reply": "2023-11-25T22:03:56.661909Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0x6098126de510 SumBackward\n",
      "  0x6098126bc270 AddBackward\n",
      "    0x6098126e08f0  \n",
      "    0x6098126e08f0  \n"
     ]
    }
   ],
   "source": [
    "loss.graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T22:03:56.663833Z",
     "iopub.status.busy": "2023-11-25T22:03:56.663700Z",
     "iopub.status.idle": "2023-11-25T22:03:56.667044Z",
     "shell.execute_reply": "2023-11-25T22:03:56.666721Z"
    }
   },
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import io\n",
    "import re\n",
    "\n",
    "with io.StringIO() as buf, contextlib.redirect_stdout(buf):\n",
    "    help(Tensor)\n",
    "    HELP = re.split(\"-{5,}\", buf.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now this includes the barebones to make a Multi-Layer perceptron:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T22:03:56.668217Z",
     "iopub.status.busy": "2023-11-25T22:03:56.668081Z",
     "iopub.status.idle": "2023-11-25T22:03:56.670444Z",
     "shell.execute_reply": "2023-11-25T22:03:56.670195Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__(self: cudagrad.tensor.Tensor, arg0: cudagrad.tensor.Tensor) -> cudagrad.tensor.Tensor',\n",
       " '__init__(self: cudagrad.tensor.Tensor, arg0: list[int], arg1: list[float]) -> None',\n",
       " '__matmul__(self: cudagrad.tensor.Tensor, arg0: cudagrad.tensor.Tensor) -> cudagrad.tensor.Tensor',\n",
       " '__mul__(self: cudagrad.tensor.Tensor, arg0: cudagrad.tensor.Tensor) -> cudagrad.tensor.Tensor',\n",
       " '__repr__(self: cudagrad.tensor.Tensor) -> str',\n",
       " '__str__(self: cudagrad.tensor.Tensor) -> str',\n",
       " '__sub__(self: cudagrad.tensor.Tensor, arg0: cudagrad.tensor.Tensor) -> cudagrad.tensor.Tensor',\n",
       " '__truediv__(self: cudagrad.tensor.Tensor, arg0: cudagrad.tensor.Tensor) -> cudagrad.tensor.Tensor',\n",
       " 'backward(self: cudagrad.tensor.Tensor) -> None',\n",
       " 'get_shared(self: cudagrad.tensor.Tensor) -> cudagrad.tensor.Tensor',\n",
       " 'graph(self: cudagrad.tensor.Tensor) -> None',\n",
       " 'item(self: cudagrad.tensor.Tensor) -> float',\n",
       " 'relu(self: cudagrad.tensor.Tensor) -> cudagrad.tensor.Tensor',\n",
       " 'sigmoid(self: cudagrad.tensor.Tensor) -> cudagrad.tensor.Tensor',\n",
       " 'sum(self: cudagrad.tensor.Tensor) -> cudagrad.tensor.Tensor',\n",
       " 'zero_grad(self: cudagrad.tensor.Tensor) -> None']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x[2:].strip() for x in HELP[0].splitlines() if \"(self:\" in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Tensor([2, 1, ], [0, 2, ]) object at 0x609810a35e70 AddBackward>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t + t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0],\n",
      " [0, 1]]\n",
      "[[0, 0],\n",
      " [0, 0]]\n"
     ]
    }
   ],
   "source": [
    "# FIXME repr truncates\n",
    "print(t @ Tensor([1, 2], range(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Tensor([2, 1, ], [0, 1, ]) object at 0x6098125cf710 MulBackward>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t * t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Tensor([2, 1, ], [0, 0, ]) object at 0x6098126c4890 MinusBackward>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t - t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Tensor([2, 1, ], [-nan, 1, ]) object at 0x6098126e0060 DivBackward>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FIXME nan\n",
    "t / t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method PyCapsule.backward of <Tensor([2, 1, ], [0, 1, ]) object at 0x6098126e08f0 DefaultBackward>>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Tensor([2, 1, ], [0, 1, ]) object at 0x6098126e08f0 DefaultBackward>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FIXME remove binding\n",
    "t.get_shared()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.data[[0,0]].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Tensor([1, ], [0, ]) object at 0x6098126e9200 SelectBackward>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.data[[0, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.data[[0, 0]].item(), t.data[[1, 0]].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FIXME bounds check?\n",
    "t.data[[1, 1]].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Tensor([2, ], [0, 0.5, ]) object at 0x6098124f9f20 ReluBackward>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tensor.relu(Tensor([2], [-0.5, 0.5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Tensor([2, ], [0.377541, 0.622459, ]) object at 0x6098126db7b0 SigmoidBackward>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tensor.sigmoid(Tensor([2], [-0.5, 0.5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Tensor([1, ], [1, ]) object at 0x6098126de2f0 SumBackward>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0],\n",
      " [1]]\n",
      "[[0],\n",
      " [4.2]]\n"
     ]
    }
   ],
   "source": [
    "t.grad[[0, 1]] = 4.2\n",
    "\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0],\n",
      " [1]]\n",
      "[[0],\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "t.zero_grad()\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor static methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T22:03:56.687287Z",
     "iopub.status.busy": "2023-11-25T22:03:56.687182Z",
     "iopub.status.idle": "2023-11-25T22:03:56.689568Z",
     "shell.execute_reply": "2023-11-25T22:03:56.689317Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['explode(arg0: list[int], arg1: float) -> cudagrad.tensor.Tensor',\n",
       " 'ones(arg0: list[int]) -> cudagrad.tensor.Tensor',\n",
       " 'rand(arg0: list[int]) -> cudagrad.tensor.Tensor',\n",
       " 'zeros(arg0: list[int]) -> cudagrad.tensor.Tensor']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x[2:].strip() for x in HELP[1].splitlines() if \"(arg0:\" in x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These turn out to be very helpful, `explode` is the only way to do broadcast at the moment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Tensor([2, ], [0, 0, ]) object at 0x6098126c9cd0 DefaultBackward>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tensor.zeros([2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Tensor([2, ], [1, 1, ]) object at 0x6098126df1a0 DefaultBackward>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tensor.ones([2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Tensor([2, ], [0.0225735, 0.687413, ]) object at 0x6098126df3f0 DefaultBackward>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tensor.rand([2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how `explode` has a slightly different signature: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T22:03:56.690793Z",
     "iopub.status.busy": "2023-11-25T22:03:56.690651Z",
     "iopub.status.idle": "2023-11-25T22:03:56.692812Z",
     "shell.execute_reply": "2023-11-25T22:03:56.692562Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Tensor([2, ], [4.2, 4.2, ]) object at 0x6098126e09d0 DefaultBackward>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tensor.explode([2], 4.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor readonly properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T22:03:56.694084Z",
     "iopub.status.busy": "2023-11-25T22:03:56.693901Z",
     "iopub.status.idle": "2023-11-25T22:03:56.696188Z",
     "shell.execute_reply": "2023-11-25T22:03:56.695971Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data', 'grad', 'size']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x[2:].strip() for x in HELP[2].splitlines()[2:] if x[2:].strip() != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 1.0]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 2, 1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(t.size), t.size[0], t.size[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
