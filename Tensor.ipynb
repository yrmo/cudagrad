{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is documentation for `cudagrad.Tensor`.\n",
    "\n",
    "The neural networks included in cudagrad are written purely in Python, using only the `cudagrad.Tensor`. Ideally, this helps improve the `Tensor` class over time. Please see the GitHub [repository](https://github.com/yrmo/cudagrad) for examples of it's current capabilities ([flexing](https://youtu.be/VMj-3S1tku0?t=271s)).\n",
    "\n",
    "# Warnings ðŸ²ðŸ‰\n",
    "\n",
    "This is an experimental learning project and will be unstable until version 1.0.0 as per [SemVer-4](https://semver.org/):\n",
    "\n",
    "> Major version zero (0.y.z) is for initial development. Anything MAY change at any time. The public API SHOULD NOT be considered stable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T22:03:55.886940Z",
     "iopub.status.busy": "2023-11-25T22:03:55.886331Z",
     "iopub.status.idle": "2023-11-25T22:03:55.904779Z",
     "shell.execute_reply": "2023-11-25T22:03:55.903889Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.0.51'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cudagrad\n",
    "\n",
    "cudagrad.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that in the long-term, optimizations will be done with only nvcc in mind.\n",
    "\n",
    "## 0.0.48+ â€“ nvcc only*\n",
    "\n",
    "These are **broken** experiments as work is done to make pybind11 use nvcc.\n",
    "\n",
    "*There may continue to be support for an unoptimized CPU version of cudagrad, installable without nvcc.\n",
    "\n",
    "## 0.0.47 â€“ gcc or clang\n",
    "\n",
    "Support for gcc was added to make the transition to nvcc easier, as nvcc uses gcc as the host compiler on Ubuntu.\n",
    "\n",
    "### Broken on newer versions of pip\n",
    "\n",
    "There was a change to pip causing a runtime warning to become a runtime error during installation. The error is an (unused) external dependency being declared outside of the pyproject.toml.\n",
    "\n",
    "### Broken if nvcc command is not found\n",
    "\n",
    "While you only truly need gcc (or clang), there is an unneeded check during installation (Python `which`) to see if nvcc is present during installation. The check can be bypassed by making a dummy nvcc command:\n",
    "\n",
    "```sh\n",
    "echo 'export PATH=$PATH:/usr/local/bin' >> ~/.bashrc && source ~/.bashrc && echo -e '#!/bin/bash\\necho \"Dummy nvcc command\"' > /usr/local/bin/nvcc && chmod +x /usr/local/bin/nvcc\n",
    "```\n",
    "\n",
    "## 0.0.46- â€“Â clang only\n",
    "\n",
    "Can only be installed with clang but not gcc. Tested on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple clang version 14.0.3 (clang-1403.0.22.14.1)\n",
      "Target: arm64-apple-darwin22.3.0\n",
      "Thread model: posix\n",
      "InstalledDir: /Library/Developer/CommandLineTools/usr/bin\n",
      "Python 3.11.1\n",
      "pip 23.1.2 from /Users/ryan/.pyenv/versions/3.11.1/lib/python3.11/site-packages/pip (python 3.11)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import system\n",
    "\n",
    "system(\"clang --version\")\n",
    "system(\"python --version\")\n",
    "system(\"pip --version\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Installation\n",
    "\n",
    "[Available on PyPi](https://pypi.org/project/cudagrad/), use `pip install cudagrad` to install.\n",
    "\n",
    "As a warning, NVIDIA's [`nvcc`](https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html) compiler must be installed on the system for `pip install cudagrad` to work, as cudagrad is a [C++ extension to Python](https://docs.python.org/3/extending/building.html) (using [pybind11](https://github.com/pybind/pybind11))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cudagrad tensors are like PyTorch tensors, except:\n",
    "\n",
    "- Tensors only use `float32`\n",
    "- Tensors `requires_grad` by default\n",
    "- The `Tensor` constructor takes two lists instead of a nested list: cg.Tensor([size], [data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor `__init__`\n",
    "\n",
    "The data list is loaded in [row-major order](https://en.wikipedia.org/wiki/Row-_and_column-major_order) (left to right, top to bottom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T22:03:55.932395Z",
     "iopub.status.busy": "2023-11-25T22:03:55.931839Z",
     "iopub.status.idle": "2023-11-25T22:03:55.935000Z",
     "shell.execute_reply": "2023-11-25T22:03:55.934738Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cudagrad.Tensor([2, 1, ], [0, 1, ]) object at 0x1025db580>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cudagrad import Tensor\n",
    "\n",
    "T = Tensor([2, 1], range(2))\n",
    "T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We made a tensor that is a column matrix with the values of 0, and 1. This would be the same as the following in PyTorch for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T22:03:55.936396Z",
     "iopub.status.busy": "2023-11-25T22:03:55.936301Z",
     "iopub.status.idle": "2023-11-25T22:03:56.648365Z",
     "shell.execute_reply": "2023-11-25T22:03:56.647759Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [1.]], requires_grad=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.tensor([[0], [1]], dtype=torch.float32, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we `print` this tensor two matrixes are printed, first the `data`, then the `grad`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T22:03:56.653908Z",
     "iopub.status.busy": "2023-11-25T22:03:56.653775Z",
     "iopub.status.idle": "2023-11-25T22:03:56.655706Z",
     "shell.execute_reply": "2023-11-25T22:03:56.655447Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0],\n",
      " [1]]\n",
      "[[0],\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "print(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Various operations are supported, far fewer than PyTorch, but I plan to grow this over time... At the moment some basics are supported:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T22:03:56.657134Z",
     "iopub.status.busy": "2023-11-25T22:03:56.657001Z",
     "iopub.status.idle": "2023-11-25T22:03:56.659111Z",
     "shell.execute_reply": "2023-11-25T22:03:56.658870Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cudagrad.Tensor([1, ], [2, ]) object at 0x145ecc4d8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = (T + T).sum()\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might wondering why I show the address of the Tensor object, unlike PyTorch. It's because it's helpful for debugging, I use this myself for cudagrad's development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T22:03:56.660516Z",
     "iopub.status.busy": "2023-11-25T22:03:56.660387Z",
     "iopub.status.idle": "2023-11-25T22:03:56.662275Z",
     "shell.execute_reply": "2023-11-25T22:03:56.661909Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0x145ecc4d8 s\n",
      "  0x145ecd8d8 +\n",
      "    0x1025db580  \n",
      "    0x1025db580  \n"
     ]
    }
   ],
   "source": [
    "loss.graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm a big fan of introspection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is some gross stuff to turn the `help` into a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T22:03:56.663833Z",
     "iopub.status.busy": "2023-11-25T22:03:56.663700Z",
     "iopub.status.idle": "2023-11-25T22:03:56.667044Z",
     "shell.execute_reply": "2023-11-25T22:03:56.666721Z"
    }
   },
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import io\n",
    "import re\n",
    "\n",
    "with io.StringIO() as buf, contextlib.redirect_stdout(buf):\n",
    "    help(Tensor)\n",
    "    HELP = re.split(\"-{5,}\", buf.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T22:03:56.668217Z",
     "iopub.status.busy": "2023-11-25T22:03:56.668081Z",
     "iopub.status.idle": "2023-11-25T22:03:56.670444Z",
     "shell.execute_reply": "2023-11-25T22:03:56.670195Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__(self: cudagrad.tensor.Tensor, arg0: cudagrad.tensor.Tensor) -> cudagrad.tensor.Tensor',\n",
       " '__init__(self: cudagrad.tensor.Tensor, arg0: List[int], arg1: List[float]) -> None',\n",
       " '__matmul__(self: cudagrad.tensor.Tensor, arg0: cudagrad.tensor.Tensor) -> cudagrad.tensor.Tensor',\n",
       " '__mul__(self: cudagrad.tensor.Tensor, arg0: cudagrad.tensor.Tensor) -> cudagrad.tensor.Tensor',\n",
       " '__repr__(self: cudagrad.tensor.Tensor) -> str',\n",
       " '__str__(self: cudagrad.tensor.Tensor) -> str',\n",
       " '__sub__(self: cudagrad.tensor.Tensor, arg0: cudagrad.tensor.Tensor) -> cudagrad.tensor.Tensor',\n",
       " '__truediv__(self: cudagrad.tensor.Tensor, arg0: cudagrad.tensor.Tensor) -> cudagrad.tensor.Tensor',\n",
       " 'backward(self: cudagrad.tensor.Tensor) -> None',\n",
       " 'get_shared(self: cudagrad.tensor.Tensor) -> cudagrad.tensor.Tensor',\n",
       " 'graph(self: cudagrad.tensor.Tensor) -> None',\n",
       " 'item(self: cudagrad.tensor.Tensor) -> float',\n",
       " 'relu(self: cudagrad.tensor.Tensor) -> cudagrad.tensor.Tensor',\n",
       " 'sigmoid(self: cudagrad.tensor.Tensor) -> cudagrad.tensor.Tensor',\n",
       " 'sum(self: cudagrad.tensor.Tensor) -> cudagrad.tensor.Tensor',\n",
       " 'zero_grad(self: cudagrad.tensor.Tensor) -> None']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x[2:].strip() for x in HELP[0].splitlines() if \"(self:\" in x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now this includes the barebones to make a Multi-Layer perceptron:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T22:03:56.671642Z",
     "iopub.status.busy": "2023-11-25T22:03:56.671515Z",
     "iopub.status.idle": "2023-11-25T22:03:56.674426Z",
     "shell.execute_reply": "2023-11-25T22:03:56.674150Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2794.0]\n",
      "[1]\n",
      "[143.0, 187.0, 143.0, 187.0]\n",
      "[66.0, 66.0, 88.0, 88.0]\n"
     ]
    }
   ],
   "source": [
    "a = Tensor([2, 2], [2.0, 3.0, 4.0, 5.0])\n",
    "b = Tensor([2, 2], [6.0, 7.0, 8.0, 9.0])\n",
    "c = Tensor([2, 2], [10.0, 10.0, 10.0, 10.0])\n",
    "d = Tensor([2, 2], [11.0, 11.0, 11.0, 11.0])\n",
    "e = Tensor.relu(((a @ b) + c) * d)\n",
    "f = e.sum()\n",
    "f.backward()\n",
    "\n",
    "# Several awful things going on here, working on it!\n",
    "print([f.data[[0]].item()])\n",
    "print(f.size)\n",
    "print(\n",
    "    [\n",
    "        a.grad[[0, 0]].item(),\n",
    "        a.grad[[0, 1]].item(),\n",
    "        a.grad[[1, 0]].item(),\n",
    "        a.grad[[1, 1]].item(),\n",
    "    ]\n",
    ")\n",
    "print(\n",
    "    [\n",
    "        b.grad[[0, 0]].item(),\n",
    "        b.grad[[0, 1]].item(),\n",
    "        b.grad[[1, 0]].item(),\n",
    "        b.grad[[1, 1]].item(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T22:03:56.675640Z",
     "iopub.status.busy": "2023-11-25T22:03:56.675452Z",
     "iopub.status.idle": "2023-11-25T22:03:56.686089Z",
     "shell.execute_reply": "2023-11-25T22:03:56.685808Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2794.)\n",
      "torch.Size([])\n",
      "tensor([[143., 187.],\n",
      "        [143., 187.]])\n",
      "tensor([[66., 66.],\n",
      "        [88., 88.]])\n"
     ]
    }
   ],
   "source": [
    "at = torch.tensor(((2.0, 3.0), (4.0, 5.0)), requires_grad=True)\n",
    "bt = torch.tensor(((6.0, 7.0), (8.0, 9.0)), requires_grad=True)\n",
    "ct = torch.tensor(((10.0, 10.0), (10.0, 10.0)), requires_grad=True)\n",
    "dt = torch.tensor(((11.0, 11.0), (11.0, 11.0)), requires_grad=True)\n",
    "et = torch.relu(((at @ bt) + ct) * dt)\n",
    "ft = et.sum()\n",
    "ft.backward()\n",
    "\n",
    "print(ft.data)\n",
    "print(ft.size())\n",
    "print(at.grad)\n",
    "print(bt.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor static methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T22:03:56.687287Z",
     "iopub.status.busy": "2023-11-25T22:03:56.687182Z",
     "iopub.status.idle": "2023-11-25T22:03:56.689568Z",
     "shell.execute_reply": "2023-11-25T22:03:56.689317Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['explode(arg0: List[int], arg1: float) -> cudagrad.tensor.Tensor',\n",
       " 'ones(arg0: List[int]) -> cudagrad.tensor.Tensor',\n",
       " 'rand(arg0: List[int]) -> cudagrad.tensor.Tensor',\n",
       " 'zeros(arg0: List[int]) -> cudagrad.tensor.Tensor']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x[2:].strip() for x in HELP[1].splitlines() if \"(arg0:\" in x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These turn out to be very helpful, `explode` is the only way to do broadcast at the moment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T22:03:56.690793Z",
     "iopub.status.busy": "2023-11-25T22:03:56.690651Z",
     "iopub.status.idle": "2023-11-25T22:03:56.692812Z",
     "shell.execute_reply": "2023-11-25T22:03:56.692562Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cudagrad.Tensor([2, ], [4.2, 4.2, ]) object at 0x12d39eb08>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tensor.explode([2], 4.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor readonly properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-25T22:03:56.694084Z",
     "iopub.status.busy": "2023-11-25T22:03:56.693901Z",
     "iopub.status.idle": "2023-11-25T22:03:56.696188Z",
     "shell.execute_reply": "2023-11-25T22:03:56.695971Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data', 'grad', 'size']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x[2:].strip() for x in HELP[2].splitlines()[2:] if x[2:].strip() != \"\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what that would look like using PyTorch:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
